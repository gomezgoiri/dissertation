\section{Evaluation}
\label{sec:search_evaluation}

\subsection{Types of clues shared}
\label{sec:clues_eval}
As presented in Section~\ref{sec:clues}, the type of clue used will affect
\begin{enumerate*}[label=\itshape(\arabic*\upshape)]
  \item the \emph{precision} and \emph{recall} to find the nodes with the appropriate information; and % explained in section 4
  \item the amount of information to transfer over the network (both requests and responses) and nodes have to process.
\end{enumerate*}
Increasing \emph{precision} reduces the number of unsuccessful requests to handle and thus, it reduces the energy consumption. 
Similarly, sending more information over the network implies more processing time and more energy consumption.

\medskip

\noindent\textbf{Precision and recall.}
We evaluate the \emph{precision} and the \emph{recall} of the proposed algorithm in a network of 470 nodes issuing the query templates shown in Table~\ref{tab:evaluationTemplates}.
In average, the nodes manage instances belonging to 6.34 different classes (standard deviation, $SD=1.31$) among a total of 17 distinct classes in the \Space{}.
%When these classes are expanded with a reasoning process, the nodes store 20 different concepts among a total of 113 classes in the space ($SD=4$). % TODO actualizar
The distinct predicates managed by each node in average are 16.01 ($SD=1.53$) out of 68 different predicates in the \Space{}.


\newcommand{\tplone}{\emph{T1}}
\newcommand{\tpltwo}{\emph{T2}}
\newcommand{\tplthree}{\emph{T3}}
\newcommand{\tplfour}{\emph{T4}}
\newcommand{\tplfive}{\emph{T5}}


\input{\pathchapfive/tables/evaluation_templates}
% Las consultas se podrían sacar también de bizkaisense o alguna app que hayamos hecho para darle mayor verosimilitud


% Explicar class based
In Figures~\ref{fig:recall_measures}~and~\ref{fig:precision_measures}, the class-based clue shows a good \emph{precision} and \emph{recall} for \tplone{} and \tpltwo{}.
\tplone{} asks exactly for the information this type of clues define (i.e., nodes having instances of a certain class).
\tpltwo{} evaluates which nodes have instances in the domain of the \emph{long} predicate (\emph{SpatialThing}).
Note that this works thanks to the \acs{rdfs} inference because some nodes in the \Space{} only write \emph{Point} instances (a subclass of \emph{SpatialThing}).
% TODO esto no se entiende muy bien sin explicación extra!
The domain of \tplthree{} and \tplfive{}'s predicates could not be inferred just using \acs{rdfs} inference. % (some properties of OWL are used => inverseof).
Even solving this limitation, we would expect a bad \emph{precision} since both predicates relate very general concepts.
In addition, when a class-based clue has no enough information to predict the nodes, it simply floods the query.
This is why the \emph{recall} of \tplfour{} is high.



\InsertFig{clues_recall}{fig:recall_measures}{\emph{Recall} for each type of clue used}{}{1}{}

\InsertFig{clues_precision}{fig:precision_measures}{\emph{Precision} for each type of clue used}{}{1}{}
% IG: TODO mencionar en el texto de referencia o en la caption algo como: The higher the better.

% Explicar predicate-based
We can see a bad prediction for \tplone{} and \tplfour{} for predicate-based clues.
\tplone{} defines a very common predicate and therefore, it cannot discriminate any node.
\tplfour{} suffers the same problem explained for the class-based clues.
We proposed a possible solution for this problem in Section~\ref{sec:aboxinclues}.

% Explicar prefix-based
Finally, prefix-based clue shows a slightly better \emph{precision} for \tplfour{}, since it can discriminate some nodes not using the \emph{bizkaisense} prefix.
On the other hand, it obtains marginally worse \emph{precision} than predicate-based clues for \tplthree{} and \tplfive{}.
% TODO reexplicar esto, no se entiende!
This worsening could be greater if few nodes using the prefixes \emph{ssn} and \emph{dc} used the predicates defined in both templates.

\medskip

\noindent\textbf{Verbosity.}
% Una frase para retomar lo anterior, y al grano.
The clues verbosity is also a critical aspect for resource constrained devices.
Figure~\ref{fig:clueSize} shows a higher variance for prefix-based clues' length and lower verbosity of class based clues.
This is because the nodes virtually have a different number of sensors.
In addition, the links to concepts of other ontologies vary within the datasets used in the parametrization.
In any case, the diagram shows a similar verbosity for all the clues for the semantic content considered in this evaluation. % TODO analizar si la media varía significativamente
% No es adecuado para cacharros pequeños: poner evaluación de WoT de inferencia


\InsertFig{clues_length}{fig:clueSize}{
  Length of the clues alternatives
}{
}{0.6}{}

% Añadir nuevas barras: Predicate+schema y predicate+schema+MostCommonsIndividuals
% Poner otra barra para saber cuanto contenido semántico guarda un nodo de media en el experimento?
% Comentar que cabe en MTU de ethernet y UDP en caso de querer enviarlo por CoAP


% TODO Añadir nuevo diagrama para el gossiping agregado y ver como crece a más elementos añadidos

\medskip

\noindent\textbf{Summary.}
Class-based clues are useful for templates asking for a specific type of content.
However, they still require inference to obtain a good \emph{precision}.
In \citet{gomez-goiri_restful_2012}, we tested the inference process on the devices and data used in this simulation.
We could not run any reasoner in the ConnectPort X2 Gateway.
Actually, we could only run \acs{rdfs} reasoners in more powerful embedded and mobile devices such as the FoxG20 and the Samsung Galaxy Tab.
In the FoxG20, it took 48.9 seconds the first load of all the ontologies used and 1.4 seconds to reason over each measurement written.
In a Samsung Galaxy Tab, it took 17.3 seconds and 0.2 the following measurement writings.
Considering these results, we can conclude that there is a clear need for efficient embedded reasoners.
Therefore, the class-based approach is promising but it is impossible to adopt in current embedded and mobile devices.

Between the predicate-based and prefix-based clues, we propose to use the predicate-based clues since they subsume much of the information provided by the prefix-based clues.
The rest of the prefixes are referred in the subjects or the objects.
They could be easily added to predicate-based clues on the prefixes field.
In addition to the use of predicate-based clues, we could implement the solution for the specific individual search proposed in Section~\ref{sec:aboxinclues}.

% Posible TODO
% GRAFICO 3: \emph{precision} y \emph{recall} comparando con y sin de cada uno

% GRAFICO 4: tamaño de gossiping individual y agregado comparando con y sin cada uno
%            (barra con barra superpuesta encima con cuanto más añade)
%            Según hay más nodos, cómo crece el gossiping a manejar?


% Discussion: ¿elegir un tipo u otro dependiendo del modo de operación?
% (i.e., si hay que perder precisión a costa de no intercambiar MBs...)
% AG: Interesante, pero yo no complicaría una sección ya de por si bastante liosa.


% TODOs importantes que me gustaria hacer para la siguiente version:
%   - Ver cómo crecen los clues agregados.
%   - Proponer una clue híbrida que mezcle a las anteriores.
%   - Evaluar de alguna forma la mejora propuesta para ABox.



\subsection{Network usage} % IG: network role
\label{sec:NetworkUsage}

% Donde ``explicar'' negative broadcasting y/o centralizado? En seccion 4?
% Explicar porque no se pone centralizado en la comparación
%    No es directamente comparable dado que depende directamente de otro factor distinto: frecuencia de escritura.

We conduct a simulation study to evaluate the benefits of our solution against a flooding-based approach (i.e., \ac{nb}).
In addition, to give a more exhaustive comparison, we implement and test query caching on top of \ac{nb}.
We simulate multiple nodes that join the same \Space{} as \providers{} and periodically write new information to the \Space{}.
During one hour, 1 or 100 \consumers{} perform 1000 queries in total using the templates described in Table~\ref{tab:evaluationTemplates}.

As expected, our solution scales much better than the one with \ac{nb} (Figure~\ref{fig:requestsByStrategies}).
However, adding caching to \ac{nb} works slightly better than our solution with just one node querying the \Space{}.
This is due to the limited amount of different query templates used in the simulation.
When we increase the number of \consumers{} in the \Space{}, the caching strategy behaves closer to the \ac{nb}.
In the same situation, our solution handles better an increase on the number of \consumers{} in the \Space{}.


\InsertFig{requests_by_strategies}{fig:requestsByStrategies}{
  Required requests for \acf{nb}, \ac{nb} with caching with 1 and 100 \consumers{} and our solution with 1 and 100 \consumers{}
}{
}{0.75}{}


In Figure~\ref{fig:requestsByRoles}, we take a closer look to the origin of the traffic of our approach in a \Space{} with 100 \consumers{}.
The communication between the \providers{} and the \ac{wp} is much more infrequent than the other communication types.
The reason is that writing into a node only results in a clue update when the structure of the managed information changes.
The first time the metadata about the node (sensor) is written, the second time the first measure and following writings, just add or replace a measure.
Therefore, the clue does not change after the second step.
This matches with the assumption made to share \emph{TBox} information in our clues.

The communication between \consumers{} and \ac{wp} is in between the other two communication patterns.
It is greater than the one from \providers{} to \ac{wp} because \consumers{} need to maintain an updated view of the \Space{}.
Recall that the update time depends on the query frequency of each \consumer{}.
The maximum and minimum updating frequency were set to 10 and 1 minute(s) respectively.

The communications between \consumers{} and \providers{} assumes most of the total communications.
This shows that the overhead added by the use of \ac{wp} on our solution is not significant and it is justified by the reduction of the total number of communications shown in Figure~\ref{fig:requestsByStrategies}.


\InsertFig{requests_by_roles}{fig:requestsByRoles}{Requests between roles in our solution in a \Space{} with 100 \consumers{}}{}{0.75}{}



\subsection{Energy consumption}
\label{sec:energyConsumption}
% Idea: Lo de arriba está muy bien, pero específicamente, cómo afecta a los cacharros?
Our solution tries to save energy by making \providers{} handle fewer requests from \consumers{}.
These savings contrast to the overhead added by the communication with the \ac{wp}.
However, our results demonstrate that this overhead is small in comparison to the total number of communications.

The energy consumption in mobile and embedded devices increases each time a device needs to process something or communicate with another node (see Figure~\ref{fig:energy_consumption}).
To analyse how communications impact their energy autonomy, we have to consider not only the number of communications but also their time length (see Table~\ref{tab:measuresEmbedded}).
For example, a mobile phone will consume less energy asking clues to a server than asking them to an embedded device as it has to wait less for the response.


\InsertFig{energy_consumption}{fig:energy_consumption}{Average power consumption for FoxG20 during different activity periods}{}{0.6}{}


The experiment consists of 300 nodes joined to a \Space{} running on 1 server, 30 galaxy tabs, 75 FoxG20 and 194 XBees.
We increase the number of devices as their price and capacity decrease.
Using this approach, we mimic a typical \Space{} where cheap devices are more common.

As shown in Figure~\ref{fig:activity_measures}, our solution reduces the activity of each device by more than 5 times compared to \acl{nb}.
The diagram on the right details the average activity for each type of device.

In our solution, we can check how the load moves from the embedded devices (XBee and FoxG20) to the server (which is indeed chosen as a \ac{wp}).
The exceptional activity registered by the Galaxy Tabs is caused by their extremely high response time.
% This implies that handling a request in the Galaxy Tab takes much longer than the average.
However, we plan to reduce this response time changing the \acs{http} library used in our Android implementation.


\InsertFig{activity_measures}{fig:activity_measures}{Activity time for each strategy}{
  The first part shows the average active time a node spends on each strategy.
  The second one shows the active time classified by the type of device each node has run on.
}{1}{}
% TODO añadir a la derecha los valores en NB?

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% QUIZA para 2da VERSION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  + Vamos a medir y comparar distintas situaciones entre sí:
%   Nota: cuando hablo de servidor, movil o dispositivo embebido, ejemplifico capacidades.
%         dispositivo embebido puede almacenar menos cosas y hace consultas más concretas.
%
%      - Situación 1: Negative broadcasting (o todo dispositivos embebidos)
%      - Situación 2: 1 servidor (WP), 20 moviles, 120 dispositivos embebidos (proporción 1:20:120)
%      - Situación 3: 20 moviles, 120 dispositivos embebidos (proporción 1:6, entre móviles 5 con el cargador enchufado)
%      - Situación 4: todo dispositivos embebidos
%  + Eje Y: Tiempo medio en ejecución
%  + Eje X: A parte de las situaciones (ver esquema de \emph{recall}) algún otro aspecto que también afecte al consumo de energía:
%      - número de consultas?
%      - frecuencia de las mismas?
%      - nodos consultores?



\subsection{Performance in dynamic environments}
\label{sec:dynamic}
We evaluate the network usage of our solution in ordinary situations in sections~\ref{sec:NetworkUsage} and \ref{sec:energyConsumption}.
Nevertheless, we do not evaluate scenarios where the nodes frequently join and leave the \Space{}.
In such situation, the communication needed to manage the clues might be a burden.


\InsertFig{dynamism}{fig:dynamic_situations}{Effects of dynamic scenarios in our solution}{
  Note that the last interval in the x-axis represents a simulation with no drops.
}{1}{}


To assess the effect of dynamic networks on the performance of our solution, we used the scenario presented in Section~\ref{sec:energyConsumption},
Then, we simulate nodes joining and leaving the \Space{} at different intervals: 30 seconds, 1 minute, 5 minutes, 10 minutes, 20 minutes, 30 minutes, 45 minutes.
Particularly, for our solution, we tested the most harmful situation: the node leaving the \Space{} abruptly is always the \ac{wp}.
We also added an scenario with no drops as a baseline.
Note that we represent this scenario by configuring the drop-interval with a greater value than the simulation time.

In Figure~\ref{fig:dynamic_situations}, we see the results of these simulations.
These results show that even in such dynamic situations, our solution requires fewer communications than \acl{nb}.
In our solution, most of the communications are between \consumers{} and \providers{}.
To evaluate the overhead added by our solution, the graphic on the right hand side shows the communications involving \acp{wp}.

We can appreciate that the updates on \consumers{} are independent of the number of times the \ac{wp} changes.
We can also see a minimal change between the scenario where the \ac{wp} is always available and the one with 5 minutes drop-interval.
In this case, when the \ac{wp} drops, many \consumers{} have the latest version of the aggregated clue.
% Dado que se parte del que tenia el WP o del que le ha dado el consumer que le ha elegido. Ambos tienen más opciones de tener una versión actualizada.
This situation increases the chances of getting an updated version for the initialization of the new \ac{wp} (see Section~\ref{sec:selection}).
Thus, it reduces the number of messages from \providers{} to the new \ac{wp}.


\subsection{Effects on discovery mechanisms}
\label{sec:mdns}

We want to prove the feasibility of our solution using a common discovery mechanism.
To that end, we simulate the behaviour of the \ac{mdns} and \ac{dns-sd} \citeweb{dnssd2013} protocols.
Both protocols are based on the well known and widely accepted \ac{dns}.
\ac{dns} associates different pieces of information (i.e., records) with domain names in a distributed manner.

On the one hand, \ac{dns-sd} proposes a new use for \ac{dns}'s TXT records.
The TXT record was originally intended to associate an arbitrary human-readable text with a domain name.
\ac{dns-sd} proposes to use this type of record, to share key-value pairs in its data field.
We use these key-value pairs to share the information needed by the selection algorithm among the nodes.

On the other hand, \ac{mdns} defines how this and other records are shared through UDP multicast (or unicast in certain situations).
We ignore the cost of browsing the nodes to discover new nodes because it is the same for both strategies.
However, note that as explained above, our strategy does differ from \acl{nb} in the use of TXT records.

The nodes announce records during the start up or whenever they have a resource record with new data.
Therefore, each time a record is updated, we send a multicast message that increases the network traffic.
In our solution the TXT record may change 
\begin{enumerate*}[label=\itshape(\arabic*\upshape)]
  \item when a new \ac{wp} is selected or
  \item when we update the time elapsed since it joined the \Space{} and its battery charge level.
\end{enumerate*}
The last two parameters need to be updated to select an appropriate \ac{wp} but they do not need to change too frequently.

% Regarding the first case,  % no pillo la introduccion del first case
In the most static scenario the TXT record is written only once.
The more dynamic scenario from the previous section, on the contrary, updates that record 126 times after writing it for the first time.
This demonstrates that the overhead generated on the discovery system by our solution is minimal even in the worst-case scenario.